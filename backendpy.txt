## ---------------------------------------------------
## FINAL and COMPLETE main.py FOR PATIENT BACKEND
## ---------------------------------------------------

from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.responses import Response, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from motor.motor_asyncio import AsyncIOMotorClient, AsyncIOMotorGridFSBucket
from bson import ObjectId
from passlib.context import CryptContext
from copy import deepcopy
from datetime import datetime, timedelta, time
from typing import Optional, Any, Dict, List
import os
import asyncio
import firebase_admin
from firebase_admin import credentials, messaging
import httpx
import re
from zoneinfo import ZoneInfo
from dotenv import load_dotenv
# Add these to your existing imports
from agora_token_builder import RtcTokenBuilder
import time as time_module
import random
# Agora credentials (prefer env vars, fallback to placeholders)
AGORA_APP_ID = os.environ.get("AGORA_APP_ID") or "18201a6aca7044c6982cdd8fa6e38993"  # <--- PASTE YOUR ID HERE
AGORA_APP_CERTIFICATE = os.environ.get("AGORA_APP_CERTIFICATE") or "589ed7705d32450baff17ed100208833" # <--- PASTE CERT HERE

# Load environment variables from .env file18201a6aca7044c6982cdd8fa6e38993
load_dotenv()

# IST timezone
IST = ZoneInfo("Asia/Kolkata")

app = FastAPI(title="Patient App API")

# Allow frontend to connect
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Add exception handler for all requests
@app.middleware("http")
async def log_all_requests(request, call_next):
    """Log all incoming requests for debugging"""
    print(f"[REQUEST] {request.method} {request.url.path}")
    try:
        response = await call_next(request)
        print(f"[RESPONSE] {request.method} {request.url.path} -> {response.status_code}")
        return response
    except Exception as e:
        print(f"[REQUEST_ERROR] {request.method} {request.url.path} -> {e}")
        raise

# Basic root and health endpoints to avoid 404 noise and provide status
@app.get("/")
async def root():
    return {
        "status": "ok",
        "service": "patient-api",
        "time": datetime.utcnow().isoformat(),
    }

# Using async Motor client
mongo_url = os.environ.get("MONGO_URL") or os.getenv("MONGO_URL") or "mongodb://localhost:27017/"
client = AsyncIOMotorClient(mongo_url)
db = client["chakra_hospital"]
patients_collection = db["patients"]
submissions_collection = db["patient_submissions"]
messages_collection = db["messages"]
gridfs_bucket = AsyncIOMotorGridFSBucket(db)

# Password hashing
pwd_context = CryptContext(schemes=["bcrypt", "pbkdf2_sha256"], deprecated="auto")

print("[STARTUP] FastAPI app initialized - main.py loaded")
print("[STARTUP] App will start listening on startup...")

# initialize firebase admin if credential path provided in env
FIREBASE_CRED_PATH = r"firebase_admin.json"
try:
    if FIREBASE_CRED_PATH and not firebase_admin._apps:
        cred = credentials.Certificate(FIREBASE_CRED_PATH.strip('"'))
        firebase_admin.initialize_app(cred)
        print("Firebase admin initialized using:", FIREBASE_CRED_PATH)
        FIREBASE_INITIALIZED = True
        LAST_FIREBASE_ERROR = None
except Exception as e:
    # initialization failing should not crash the whole app; log
    print("Firebase initialization failed:", e)
    FIREBASE_INITIALIZED = False
    LAST_FIREBASE_ERROR = str(e)

# ensure flags exist even if path missing
try:
    FIREBASE_INITIALIZED
except NameError:
    FIREBASE_INITIALIZED = False
    LAST_FIREBASE_ERROR = None

# Optional: doctor backend URL to which notification delivery should be delegated.
# If set, the patient backend will POST notification docs to the doctor backend
# instead of invoking firebase_admin directly. Example: "https://doctor.example.com"
DOCTOR_BACKEND_URL = os.environ.get("DOCTOR_BACKEND_URL") or os.getenv("DOCTOR_BACKEND_URL")

# new collections
fcm_tokens_collection = db["fcm_tokens"]
notifications_collection = db["notifications"]
adherence_collection = db["adherence"]
visiontests_collection = db["visiontests"]
amsler_collection = db["amsler_tests"]
scheduled_meds_collection = db["scheduled_medicines"]
medicine_doses_collection = db["medicine_doses"]
WEEKDAY_LABELS = ["Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"]

# ---------------- Models ----------------
class LoginRequest(BaseModel):
    email: str
    password: str


class PatientSubmission(BaseModel):
    id: Optional[str] = Field(default=None, alias="_id")
    patient_id: str
    patient_name: str
    doctor_id: str
    image_file_id: str
    pain_scale: int
    vision_blur: Optional[int] = 0  # NEW
    swelling: Optional[int] = 0
    redness: Optional[int] = 0
    watering: Optional[int] = 0
    itching: Optional[int] = 0      # NEW
    discharge: Optional[int] = 0    # NEW
    comments: Optional[str] = None
    is_viewed: bool = False
    timestamp: datetime = Field(default_factory=datetime.utcnow)

# --------------- Agora Call Models ---------------
class CallInitiateRequest(BaseModel):
    doctor_id: str
    patient_id: str
    channel_name: str


# ---------------- Utils ----------------
def serialize_doc(obj: Any) -> Any:
    """Recursively convert MongoDB types to JSON-serializable types."""
    if isinstance(obj, ObjectId):
        return str(obj)
    if isinstance(obj, datetime):
        return obj.isoformat()
    if isinstance(obj, dict):
        return {k: serialize_doc(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [serialize_doc(v) for v in obj]
    return obj


def _extract_email_contact(patient: Dict[str, Any]) -> Optional[str]:
    ci = patient.get("contactInfo")
    if isinstance(ci, dict):
        return ci.get("email") or ci.get("phone")
    return patient.get("email")


def _expose_compat_fields(patient: Dict[str, Any]) -> Dict[str, Any]:
    """
    Add convenience / legacy-compatible keys so frontend can read consistent fields:
     - email, phone (top-level)
     - prescription (from doctor.prescription or drugHistory.currentMeds)
     - medicines (alias to prescription for older UI)
     - history_summary (small summary)
     - recent_encounter (computed)
     - normalize _id and created_at
    Supports BOTH old schema (top-level fields) and NEW schema (patientDetails, medicalHistory at root).
    """
    p = deepcopy(patient)

    # Normalize _id which may come as {'$oid': '...'} or ObjectId or plain str
    try:
        raw_id = p.get("_id")
        if isinstance(raw_id, dict) and raw_id.get("$oid"):
            p["_id"] = raw_id.get("$oid")
        else:
            p["_id"] = str(raw_id) if raw_id is not None else None
    except Exception:
        p["_id"] = p.get("_id")

    # NEW SCHEMA: Extract from patientDetails if present (new schema structure)
    pat_details = p.get("patientDetails") or {}
    if isinstance(pat_details, dict):
        # Map patientDetails top-level for backward compatibility
        p.setdefault("name", pat_details.get("name", p.get("name")))
        p.setdefault("email", pat_details.get("email", p.get("email")))
        p.setdefault("phone", pat_details.get("phone", p.get("phone")))
        p.setdefault("age", pat_details.get("age", p.get("age")))
        p.setdefault("sex", pat_details.get("sex", p.get("sex")))
        p.setdefault("bloodType", pat_details.get("bloodType", p.get("bloodType")))
        p.setdefault("address", pat_details.get("address", p.get("address")))
        p.setdefault("registrationId", pat_details.get("registrationId", p.get("registrationId")))

    # Normalize created_at (ensure ISO string)
    if p.get("created_at") is not None:
        try:
            # if datetime object, convert to iso
            if isinstance(p["created_at"], datetime):
                p["created_at"] = p["created_at"].isoformat()
            # if dict with $date
            elif isinstance(p["created_at"], dict) and ("$date" in p["created_at"]):
                p["created_at"] = p["created_at"]["$date"]
        except Exception:
            pass

    # top-level email/phone/address from contactInfo
    ci = p.get("contactInfo") or {}
    if isinstance(ci, dict):
        p["email"] = ci.get("email", p.get("email"))
        p["phone"] = ci.get("phone", p.get("phone"))
        p["address"] = ci.get("address", p.get("address"))

    # demographics exposures (age, sex, bloodType)
    demo = p.get("demographics") or {}
    if isinstance(demo, dict):
        p["age"] = demo.get("age", p.get("age"))
        p["sex"] = demo.get("sex", p.get("sex"))
        p["bloodType"] = demo.get("bloodType", p.get("bloodType"))

    # emergency contact exposure
    ec = p.get("emergencyContact") or {}
    if isinstance(ec, dict):
        p["emergencyContactName"] = ec.get("name")
        p["emergencyContactPhone"] = ec.get("phone")

    # prescription alias: use robust finder to get latest items (scans visits, root, and drug history)
    try:
        # Note: _find_latest_prescription_items is defined later in the file but available at runtime
        latest_items = _find_latest_prescription_items(p)
        p["prescription"] = {"items": latest_items} if latest_items else {}
        p["medicines"] = latest_items or []
    except Exception as e:
        # Fallback to legacy logic if robust finder fails or is not yet available
        doc_section = p.get("doctor") or {}
        presc_candidate = None
        if isinstance(doc_section, dict):
            presc_candidate = doc_section.get("prescription")
        if not presc_candidate:
            dh = p.get("drugHistory") or {}
            if isinstance(dh, dict):
                presc_candidate = dh.get("currentMeds") or dh.get("previousMeds")
        if not presc_candidate:
            presc_candidate = p.get("prescription")
        p["prescription"] = presc_candidate or {}
        p["medicines"] = p["prescription"]

    # history summary: small convenient object
    try:
        hist = p.get("history") or {}
        if isinstance(hist, dict):
            p["history_summary"] = {
                "severity": hist.get("severity"),
                "onset": hist.get("onset"),
                "familyHistory": hist.get("family"),
                "medical_count": len(hist.get("medical") or []),
                "surgical_count": len(hist.get("surgical") or []),
            }
    except Exception:
        p["history_summary"] = {}

    # NEW SCHEMA: medicalHistory and drugHistory at root level
    if not p.get("history_summary") or not p["history_summary"].get("familyHistory"):
        try:
            med_hist = p.get("medicalHistory") or {}
            if isinstance(med_hist, dict):
                p["history_summary"] = {
                    "severity": "",
                    "onset": "",
                    "familyHistory": med_hist.get("familyHistory", ""),
                    "medical_count": len(med_hist.get("medical") or []),
                    "surgical_count": len(med_hist.get("surgical") or []),
                }
        except Exception:
            pass

    # compute a small recent_encounter summary (if encounters present)
    try:
        encs = p.get("encounters")
        if isinstance(encs, list) and encs:
            best = None
            best_dt = None
            for e in encs:
                if not isinstance(e, dict):
                    continue
                dt = e.get("date")
                if isinstance(dt, dict):
                    dt = dt.get("$date") or dt.get("date")
                parsed = None
                if isinstance(dt, str):
                    try:
                        parsed = datetime.fromisoformat(dt.replace("Z", "+00:00"))
                    except Exception:
                        parsed = None
                if best_dt is None or (parsed and parsed > best_dt):
                    best_dt = parsed
                    best = e
            p["recent_encounter"] = best or encs[-1]
        else:
            p["recent_encounter"] = None
    except Exception:
        p["recent_encounter"] = None

    # NEW SCHEMA: extract recent_encounter from visits if present (and encounters not found)
    try:
        if not p.get("recent_encounter"):
            visits = p.get("visits")
            if isinstance(visits, list) and visits:
                # Use the most recent visit
                p["recent_encounter"] = visits[-1] if visits else None
    except Exception:
        pass

    return p


def _email_exists_in_document(doc: Dict[str, Any], email: str) -> bool:
    """
    Recursively search entire document for email (case-insensitive).
    This is a fallback for when the email is not found in known locations.
    """
    email_lower = email.lower()

    def search_recursive(obj):
        """Recursively search through nested structures"""
        if isinstance(obj, dict):
            for key, value in obj.items():
                # Check if this field's value matches the email
                if isinstance(value, str) and value.lower() == email_lower:
                    return True
                # Recurse into nested structures
                if search_recursive(value):
                    return True
        elif isinstance(obj, list):
            for item in obj:
                if search_recursive(item):
                    return True
        return False

    return search_recursive(doc)


def _extract_password_from_user(user: Dict[str, Any]) -> Optional[str]:
    """
    Two-tier password extraction strategy:

    TIER 1: Fast - Search known/common password field locations
    TIER 2: Fallback - Search nested arrays (encounters, visits) for password

    Key: Skip EMPTY STRINGS explicitly (they are falsy but block OR chain logic)
    This ensures we find passwords in nested locations even if root level has empty strings.

    Returns password string if found, None if not found anywhere.
    Robust to future schema changes - will find password in any location.
    """
    if not isinstance(user, dict):
        return None

    # Helper: Check if value is a non-empty password
    def is_valid_password(val):
        return isinstance(val, str) and len(val.strip()) > 0

    # ========== TIER 1: Fast Path (Known Field Locations) ==========
    print(f"[PASSWORD_EXTRACT] TIER 1: Searching known password field locations")

    # Root-level fields
    candidates_tier1 = [
        ("password", user.get("password")),
        ("hashed_password", user.get("hashed_password")),
    ]

    # PatientDetails fields (new schema)
    pat_details = user.get("patientDetails") or {}
    if isinstance(pat_details, dict):
        candidates_tier1.append(("patientDetails.password", pat_details.get("password")))

    # LastReception fields (nested)
    last_reception = user.get("lastReception") or {}
    if isinstance(last_reception, dict):
        last_rec_pat = last_reception.get("patientDetails") or {}
        if isinstance(last_rec_pat, dict):
            candidates_tier1.append(("lastReception.patientDetails.password", last_rec_pat.get("password")))

    # Check TIER 1 candidates (skip empty strings)
    for field_name, pwd_value in candidates_tier1:
        if is_valid_password(pwd_value):
            print(f"[PASSWORD_EXTRACT] ✓ TIER 1 SUCCESS - Found password in: {field_name}")
            return pwd_value

    print(f"[PASSWORD_EXTRACT] ✗ TIER 1 FAILED - No valid password in known locations, trying TIER 2...")

    # ========== TIER 2: Fallback Path (Nested Arrays) ==========
    print(f"[PASSWORD_EXTRACT] TIER 2: Scanning nested encounters/visits arrays")

    # Try encounters array (most recent first)
    encounters = user.get("encounters") or []
    if isinstance(encounters, list) and len(encounters) > 0:
        for idx, encounter in enumerate(encounters):
            if not isinstance(encounter, dict):
                continue

            # Check: encounters[idx].password
            if is_valid_password(encounter.get("password")):
                print(f"[PASSWORD_EXTRACT] ✓ TIER 2 SUCCESS - Found password in encounters[{idx}].password")
                return encounter.get("password")

            # Check: encounters[idx].details.patientDetails.password
            details = encounter.get("details") or {}
            if isinstance(details, dict):
                pat_det = details.get("patientDetails") or {}
                if isinstance(pat_det, dict) and is_valid_password(pat_det.get("password")):
                    print(f"[PASSWORD_EXTRACT] ✓ TIER 2 SUCCESS - Found password in encounters[{idx}].details.patientDetails.password")
                    return pat_det.get("password")

    # Try visits array (most recent first)
    visits = user.get("visits") or []
    if isinstance(visits, list) and len(visits) > 0:
        for idx, visit in enumerate(visits):
            if not isinstance(visit, dict):
                continue

            # Check: visits[idx].password
            if is_valid_password(visit.get("password")):
                print(f"[PASSWORD_EXTRACT] ✓ TIER 2 SUCCESS - Found password in visits[{idx}].password")
                return visit.get("password")

            # Check: visits[idx].stages.reception.data.patientDetails.password
            stages = visit.get("stages") or {}
            if isinstance(stages, dict):
                reception = stages.get("reception") or {}
                if isinstance(reception, dict):
                    data = reception.get("data") or {}
                    if isinstance(data, dict):
                        pat_det = data.get("patientDetails") or {}
                        if isinstance(pat_det, dict) and is_valid_password(pat_det.get("password")):
                            print(f"[PASSWORD_EXTRACT] ✓ TIER 2 SUCCESS - Found password in visits[{idx}].stages.reception.data.patientDetails.password")
                            return pat_det.get("password")

    # Ultra-robust recursive search for any password field (handles unknown future formats)
    print(f"[PASSWORD_EXTRACT] TIER 2B: Recursive search for password in any nested location...")
    def find_password_recursive(obj, depth=0, path=""):
        """Recursively search for any non-empty 'password' field"""
        if depth > 15:  # Prevent infinite recursion
            return None

        if isinstance(obj, dict):
            # Found a password field?
            if "password" in obj and is_valid_password(obj["password"]):
                print(f"[PASSWORD_EXTRACT] ✓ TIER 2B SUCCESS - Found password via recursive search at: {path}.password")
                return obj["password"]

            # Search nested dicts
            for key, value in obj.items():
                result = find_password_recursive(value, depth + 1, f"{path}.{key}" if path else key)
                if result:
                    return result

        elif isinstance(obj, list):
            # Search list items
            for idx, item in enumerate(obj):
                result = find_password_recursive(item, depth + 1, f"{path}[{idx}]")
                if result:
                    return result

        return None

    pwd = find_password_recursive(user)
    if pwd:
        return pwd

    print(f"[PASSWORD_EXTRACT] ✗ ALL TIERS FAILED - Password not found anywhere in document")
    return None


async def _find_user_by_email_or_contact(email: str) -> Optional[Dict[str, Any]]:
    """
    Two-tier email lookup strategy:
    TIER 1: Fast - Search known/common email field locations using MongoDB query
    TIER 2: Fallback - Recursively scan entire document (if Tier 1 fails)

    This ensures robustness even if email is stored in unexpected nested locations.
    """
    email_lower = email.lower()

    # ========== TIER 1: Fast Path (Known Field Locations) ==========
    print(f"[FIND_USER] TIER 1: Searching known email field locations for: {email}")

    q1 = {"$or": [
        # Root-level fields
        {"email": {"$regex": f"^{email}$", "$options": "i"}},
        {"contactInfo.email": {"$regex": f"^{email}$", "$options": "i"}},
        {"contactInfo.phone": email},
        # New schema root-level fields
        {"patientDetails.email": {"$regex": f"^{email}$", "$options": "i"}},
        {"patientDetails.phone": email},
        # Nested in encounters array
        {"encounters.details.patientDetails.email": {"$regex": f"^{email}$", "$options": "i"}},
        # Nested in lastReception
        {"lastReception.patientDetails.email": {"$regex": f"^{email}$", "$options": "i"}},
        # Nested in visits array
        {"visits.stages.reception.data.patientDetails.email": {"$regex": f"^{email}$", "$options": "i"}}
    ]}

    user = await patients_collection.find_one(q1)

    if user:
        print(f"[FIND_USER] ✓ TIER 1 SUCCESS - Found user via known field locations")
        return user

    print(f"[FIND_USER] ✗ TIER 1 FAILED - Email not in known locations, trying TIER 2 fallback...")

    # ========== TIER 2: Fallback Path (Full Document Scan) ==========
    print(f"[FIND_USER] TIER 2: Scanning all patients for email anywhere in document...")

    try:
        cursor = patients_collection.find()
        async for patient in cursor:
            if _email_exists_in_document(patient, email):
                print(f"[FIND_USER] ✓ TIER 2 SUCCESS - Found user via recursive document scan")
                return patient
    except Exception as e:
        print(f"[FIND_USER] TIER 2 ERROR: {e}")

    print(f"[FIND_USER] ✗ TIER 2 FAILED - Email not found anywhere in database")
    return None


# ============ UPDATED MEDICINE SCHEDULING HELPERS ============

def _parse_duration_days(duration_str: str, default_days: int = 7) -> int:
    """
    Parse duration strings like: "1 week", "10 days", "1 month", "30 days"
    """
    if not duration_str:
        return default_days
    s = str(duration_str).strip().lower()

    # numeric check (just "5")
    if s.isdigit():
        return int(s)

    # months -> 30 days approximate
    m = re.search(r'(\d+)\s*(month|months|mo\b)', s)
    if m:
        return int(m.group(1)) * 30

    # weeks -> 7 days
    m = re.search(r'(\d+)\s*(week|weeks|wk|w\b)', s)
    if m:
        return int(m.group(1)) * 7

    # days
    m = re.search(r'(\d+)\s*(day|days|d\b)', s)
    if m:
        return int(m.group(1))

    # word-based parsing ('one week')
    word_map = {
        "one": 1, "two": 2, "three": 3, "four": 4, "five": 5,
        "six": 6, "seven": 7, "eight": 8, "nine": 9, "ten": 10
    }
    for w, n in word_map.items():
        if f"{w} month" in s: return n * 30
        if f"{w} week" in s: return n * 7
        if f"{w} day" in s: return n

    return default_days

def _parse_times_per_day_from_text(text: str) -> int:
    """
    Extract frequency from any text string.
    Maps: "8 times", "2 times", "twice", "BD" -> int
    """
    t = str(text).lower()

    # Check for specific medical abbreviations first
    if "qid" in t: return 4
    if "tid" in t or "tds" in t or "thrice" in t: return 3
    if "bid" in t or "bd" in t or "twice" in t: return 2
    if "od" in t or "once" in t or "daily" in t: return 1

    # Generic regex to catch "X times" or just "X"
    # Matches "8 times", "8times", "8x"
    import re
    match = re.search(r'(\d+)\s*(times|x)', t)
    if match:
        return int(match.group(1))

    return 1 # Default fallback

# Schedule common medicine times (IST)
_DAYSCHEDULES = {
    1: [time(9, 0, tzinfo=IST)],
    2: [time(9, 0, tzinfo=IST), time(20, 0, tzinfo=IST)],
    3: [time(9, 0, tzinfo=IST), time(14, 0, tzinfo=IST), time(20, 0, tzinfo=IST)],
    4: [time(9, 0, tzinfo=IST), time(13, 0, tzinfo=IST), time(17, 0, tzinfo=IST), time(21, 0, tzinfo=IST)],
}

def _find_latest_prescription_items(patient_doc: dict) -> list:
    """
    ROBUST FINDER: Scans Visits, Root Prescription, and Drug History.
    Returns standardized list: [{'name':..., 'frequency':..., 'duration':...}]
    """
    items = []

    # 1. Try Visits (Sorted by Date Descending)
    visits = patient_doc.get("visits") or []
    if isinstance(visits, list) and visits:
        def get_visit_date(v):
            return v.get("visitDate") or v.get("stages", {}).get("doctor", {}).get("stageCompletedAt") or ""

        # Sort to find the very last doctor visit
        sorted_visits = sorted(visits, key=get_visit_date, reverse=True)

        for visit in sorted_visits:
            try:
                # Check stages -> doctor -> data -> prescription
                presc = visit.get("stages", {}).get("doctor", {}).get("data", {}).get("prescription", {})

                # Case A: Structure is {"items": [...]}
                if isinstance(presc, dict) and presc.get("items"):
                    return presc.get("items")

                # Case B: Key-Value pairs {"Paracetamol": "BD"}
                if isinstance(presc, dict) and presc:
                    temp_items = []
                    for k, v in presc.items():
                        if k and v:
                            temp_items.append({"name": k, "frequency": str(v), "duration": ""})
                    if temp_items:
                        return temp_items
            except Exception:
                pass

    # 2. Try Root Prescription
    root_presc = patient_doc.get("prescription")
    if isinstance(root_presc, dict) and root_presc.get("items"):
        return root_presc.get("items")

    # 3. Try Drug History (often just strings)
    drug_hist = patient_doc.get("drugHistory", {}).get("currentMeds", [])
    if isinstance(drug_hist, list) and drug_hist:
        for med in drug_hist:
            if isinstance(med, str) and med.strip():
                items.append({"name": med, "frequency": "daily", "duration": ""})
            elif isinstance(med, dict):
                items.append(med)

    # 4. Try patientDetails.medicines (New Schema)
    pd_meds = patient_doc.get("patientDetails", {}).get("medicines", [])
    if isinstance(pd_meds, list) and pd_meds:
        for med in pd_meds:
            if isinstance(med, dict):
                items.append(med)
            elif isinstance(med, str):
                items.append({"name": med, "frequency": "daily", "duration": ""})

    # 5. Try medicalHistory.drugHistory
    mh_dh = patient_doc.get("medicalHistory", {}).get("drugHistory", [])
    if isinstance(mh_dh, list) and mh_dh:
        for med in mh_dh:
            if isinstance(med, dict):
                items.append(med)

    return items

# Helper functions retained for scheduling logic
def _make_send_datetimes_for_duration(times_list: List[time], start_dt_ist: datetime, duration_days: int) -> List[str]:
    """
    Given list of time objects (IST), start datetime (IST), and duration_days,
    return list of IST-aware ISO datetimes for scheduled reminders.

    Start from start_dt_ist.date() (if the start day's time has already passed,
    scheduling for that time moves to next day).
    """
    results = []
    start_date = start_dt_ist.date()
    end_date = start_date + timedelta(days=duration_days - 1)
    now_ist = datetime.now(IST)

    day = start_date
    while day <= end_date:
        for t in times_list:
            dt_ist = datetime.combine(day, t, tzinfo=IST)
            if dt_ist <= now_ist:
                continue
            results.append(dt_ist.isoformat())
        day = day + timedelta(days=1)

    return results

def _dose_label_for_time(t: time) -> str:
    """Map a time-of-day to a human dose label."""
    h = t.hour
    if 5 <= h <= 11:
        return "Morning"
    if 12 <= h <= 16:
        return "Afternoon"
    if 17 <= h <= 20:
        return "Evening"
    return "Bedtime"

# ============ END UPDATED HELPERS ============


# ---------- Routes --------
@app.post("/login")
async def login(request: LoginRequest):
    print(f"[LOGIN] FUNCTION CALLED - email: {request.email}, password: {repr(request.password)}")

    if not request.email or not request.password:
        print(f"[LOGIN] ERROR: Email or password is empty")
        raise HTTPException(status_code=400, detail="Email and password are required")

    print(f"[LOGIN] Attempting to find user with email: {request.email}")
    user = await _find_user_by_email_or_contact(request.email)
    print(f"[LOGIN] User found: {user is not None}")
    if not user:
        print(f"[LOGIN] User NOT found - raising 404")
        raise HTTPException(status_code=404, detail="Invalid email or password")

    # Use two-tier password extraction helper (robust to all schema variations)
    stored_pw = _extract_password_from_user(user)
    if not stored_pw:
        print(f"[LOGIN] ERROR: No valid password found in user document after searching all locations")
        raise HTTPException(status_code=401, detail="Invalid email or password")

    print(f"[LOGIN] DEBUG - Password extraction successful:")
    print(f"[LOGIN]   - stored_pw type: {type(stored_pw)}")
    print(f"[LOGIN]   - stored_pw length: {len(str(stored_pw)) if stored_pw else 0}")

    # DEBUG: Log request password
    print(f"[LOGIN] DEBUG - Request password:")
    print(f"[LOGIN]   - request.password: {repr(request.password)}")
    print(f"[LOGIN]   - request.password type: {type(request.password)}")
    print(f"[LOGIN]   - request.password length: {len(request.password)}")

    # Accept both hashed and legacy plain-text passwords.
    # If stored_pw is a passlib hash, pwd_context.identify will return a scheme name;
    # otherwise fall back to a direct string comparison (for legacy records).
    try:
        is_hash = pwd_context.identify(stored_pw)
        print(f"[LOGIN] DEBUG - Password verification:")
        print(f"[LOGIN]   - is_hash (pwd_context.identify): {is_hash}")

        if is_hash:
            print(f"[LOGIN]   - Using bcrypt verification (hash detected)")
            valid = pwd_context.verify(request.password, stored_pw)
            print(f"[LOGIN]   - Hash verification result: {valid}")
        else:
            # legacy plaintext password stored in DB
            print(f"[LOGIN]   - Using plaintext comparison (no hash detected)")
            print(f"[LOGIN]   - Comparing: {repr(request.password)} == {repr(stored_pw)}")
            valid = (request.password == stored_pw)
            print(f"[LOGIN]   - Plaintext comparison result: {valid}")
    except Exception as e:
        print(f"[LOGIN] DEBUG - Password verification EXCEPTION: {e}")
        valid = False

    if not valid:
        raise HTTPException(status_code=401, detail="Invalid email or password")

    user_safe = deepcopy(user)
    user_safe.pop("password", None)
    user_safe.pop("hashed_password", None)

    user_safe = _expose_compat_fields(user_safe)
    return serialize_doc(user_safe)


@app.get("/patients")
async def get_all_patients():
    patients: List[Dict[str, Any]] = []
    cursor = patients_collection.find()
    async for p in cursor:
        p_safe = _expose_compat_fields(serialize_doc(p))
        patients.append(p_safe)
    return patients


@app.get("/patients/{patient_id}")
async def get_patient(patient_id: str):
    try:
        oid = ObjectId(patient_id)
        q = {"_id": oid}
    except Exception:
        q = {"_id": patient_id}
    p = await patients_collection.find_one(q)
    if not p:
        raise HTTPException(status_code=404, detail="Patient not found")
    p_safe = _expose_compat_fields(serialize_doc(p))
    return p_safe

# --------------- Agora Call Endpoints ---------------
# Generate a temporary RTC token for a given channel/uid
@app.post("/call/token")
async def generate_agora_token(channel_name: str, role: int = 1, uid: int = 0):
    expiration_time_in_seconds = 3600
    current_timestamp = int(time_module.time())
    privilege_expired_ts = current_timestamp + expiration_time_in_seconds

    token = RtcTokenBuilder.buildTokenWithUid(
        AGORA_APP_ID,
        AGORA_APP_CERTIFICATE,
        channel_name,
        uid,
        role,
        privilege_expired_ts,
    )
    return {"token": token, "app_id": AGORA_APP_ID}

# High-priority call notification helper to ensure ringing on devices
async def _send_call_notification(token: str, channel_name: str, agora_token: str, doctor_id: str):
    """
    Sends a HIGH PRIORITY notification specifically for calls.
    Forces the 'high_importance_channel' so it rings on Android.
    """
    if not firebase_admin._apps:
        print("[ERROR] Firebase not initialized, cannot send call notification")
        return False

    data_payload = {
        "type": "incoming_call",
        "channel_name": channel_name,
        "agora_token": agora_token,
        "app_id": AGORA_APP_ID,
        "doctor_id": doctor_id,
    }

    message = messaging.Message(
        token=token,
        notification=messaging.Notification(
            title="Incoming Video Call",
            body="Tap to answer..."
        ),
        data=data_payload,
        android=messaging.AndroidConfig(
            priority='high',
            ttl=60,
            notification=messaging.AndroidNotification(
                channel_id='call_channel_id',  # MUST MATCH FLUTTER ID
                priority='max',
                visibility='public',
                sound='ring',  # File name without extension
                click_action='FLUTTER_NOTIFICATION_CLICK'
            )
        ),
        apns=messaging.APNSConfig(
            payload=messaging.APNSPayload(
                aps=messaging.Aps(
                    content_available=True,
                    sound='ring.mp3'  # File name with extension for iOS
                )
            )
        )
    )

    try:
        response = await asyncio.to_thread(lambda: messaging.send(message))
        print(f"[CALL_PUSH] Successfully sent call notification: {response}")
        return True
    except Exception as e:
        print(f"[CALL_PUSH] Failed to send call notification: {e}")
        return False

# Initiate a call: generate patient token and send FCM push with call info
@app.post("/call/initiate")
async def initiate_call(payload: CallInitiateRequest):
    # Generate token for patient (uid 0 by convention)
    expiration_time_in_seconds = 3600
    current_timestamp = int(time_module.time())
    privilege_expired_ts = current_timestamp + expiration_time_in_seconds

    patient_token = RtcTokenBuilder.buildTokenWithUid(
        AGORA_APP_ID,
        AGORA_APP_CERTIFICATE,
        payload.channel_name,
        0,
        1,
        privilege_expired_ts,
    )

    # Lookup patient's FCM token
    fcm_doc = await fcm_tokens_collection.find_one({"patient_id": payload.patient_id})
    if not fcm_doc or not fcm_doc.get("token"):
        raise HTTPException(status_code=404, detail="Patient is not online (No FCM token found)")

    target_token = fcm_doc["token"]

    # Send HIGH PRIORITY call notification
    await _send_call_notification(
        token=target_token,
        channel_name=payload.channel_name,
        agora_token=patient_token,
        doctor_id=payload.doctor_id,
    )

    return {"status": "calling", "channel": payload.channel_name}


# --------------- Video Call Request Model ---------------
class VideoCallRequestPayload(BaseModel):
    patient_id: str
    reason: str


# Video Call Request endpoint - Patient requests a video call from their doctor
@app.post("/video-call/request", status_code=201)
async def request_video_call(payload: VideoCallRequestPayload):
    """
    Patient requests a video call from their doctor.
    Stores the request and can optionally notify the doctor.
    """
    # Find the patient to get their details and assigned doctor
    patient = await patients_collection.find_one({"_id": payload.patient_id})
    if not patient:
        # Try with ObjectId
        try:
            patient = await patients_collection.find_one({"_id": ObjectId(payload.patient_id)})
        except:
            pass

    if not patient:
        raise HTTPException(status_code=404, detail="Patient not found")

    # Get patient name and doctor info
    patient_name = patient.get("name") or patient.get("patientDetails", {}).get("name", "Unknown")
    doctor_id = patient.get("doctor_id") or patient.get("assignedDoctor", {}).get("id")

    # Create video call request record
    video_call_request = {
        "patient_id": payload.patient_id,
        "patient_name": patient_name,
        "doctor_id": doctor_id,
        "reason": payload.reason,
        "status": "pending",  # pending, accepted, rejected, completed
        "created_at": datetime.utcnow().isoformat(),
        "updated_at": datetime.utcnow().isoformat()
    }

    # Store in a video_call_requests collection
    video_call_requests_collection = db["video_call_requests"]
    result = await video_call_requests_collection.insert_one(video_call_request)

    # Optionally send notification to doctor (if doctor backend URL is configured)
    if DOCTOR_BACKEND_URL:
        try:
            async with httpx.AsyncClient() as client:
                await client.post(
                    f"{DOCTOR_BACKEND_URL}/notifications/video-call-request",
                    json={
                        "patient_id": payload.patient_id,
                        "patient_name": patient_name,
                        "reason": payload.reason,
                        "request_id": str(result.inserted_id)
                    },
                    timeout=10.0
                )
        except Exception as e:
            print(f"[VIDEO_CALL_REQUEST] Failed to notify doctor backend: {e}")

    return {
        "status": "success",
        "message": "Video call request submitted successfully",
        "request_id": str(result.inserted_id)
    }


@app.post('/patients', status_code=201)
async def create_patient(payload: Dict[str, Any]):
    """Create a new patient document.

    Accepts a full patient JSON document. If the payload contains an
    `_id` field that is a dict with `$oid`, that value will be used as the
    string id. The document is inserted as-is into the `patients` collection.
    """
    if not isinstance(payload, dict):
        raise HTTPException(status_code=400, detail='invalid payload')
    # normalize _id if provided as {'$oid': '...'}
    pid = None
    if payload.get('_id') and isinstance(payload['_id'], dict) and payload['_id'].get('$oid'):
        pid = payload['_id']['$oid']
        payload['_id'] = pid
    # ensure created_at exists
    payload.setdefault('created_at', datetime.utcnow().isoformat())
    res = await patients_collection.insert_one(payload)
    return {'status': 'created', 'patient_id': str(res.inserted_id)}


@app.put('/patients/{patient_id}')
async def upsert_patient(patient_id: str, payload: Dict[str, Any]):
    """Update or insert (upsert) a patient document by patient_id.

    This treats the `patient_id` as the document `_id` key (string). If you
    prefer ObjectId semantics, pass an actual ObjectId string and the client
    can still read it back; the server will store the id value as provided.
    Accepts both old schema (top-level fields) and new schema (patientDetails).
    """
    if not isinstance(payload, dict):
        raise HTTPException(status_code=400, detail='invalid payload')
    # set the _id in payload to the provided patient_id to keep things consistent
    payload['_id'] = patient_id
    payload.setdefault('updated_at', datetime.utcnow().isoformat())
    # Ensure lastUpdated is set for new schema
    payload.setdefault('lastUpdated', datetime.utcnow().isoformat())
    await patients_collection.update_one({'_id': patient_id}, {'$set': payload}, upsert=True)
    # return the upserted doc for convenience
    doc = await patients_collection.find_one({'_id': patient_id})
    if not doc:
        raise HTTPException(status_code=500, detail='failed to upsert patient')
    return _expose_compat_fields(serialize_doc(doc))


@app.post("/submissions", status_code=201)
async def create_submission(
    patient_id: str = Form(...),
    patient_name: str = Form(...),
    doctor_id: str = Form(...),
    pain_scale: int = Form(...),
    vision_blur: int = Form(0),
    swelling: int = Form(0),
    redness: int = Form(0),
    watering: int = Form(0),
    itching: int = Form(0),
    discharge: int = Form(0),
    comments: Optional[str] = Form(None),
    image: UploadFile = File(...),
):
    file_id = await gridfs_bucket.upload_from_stream(image.filename, image.file, metadata={"contentType": image.content_type})

    submission = PatientSubmission(
        patient_id=patient_id,
        patient_name=patient_name,
        doctor_id=doctor_id,
        pain_scale=pain_scale,
        vision_blur=vision_blur,
        swelling=swelling,
        redness=redness,
        watering=watering,
        itching=itching,
        discharge=discharge,
        comments=comments,
        image_file_id=str(file_id),
    )

    submission_dict = submission.dict(exclude={"id"}, by_alias=True)
    # add created timestamp if missing and keep flexible extra fields
    submission_dict.setdefault("created_at", datetime.utcnow().isoformat())
    result = await submissions_collection.insert_one(submission_dict)
    new_submission_id = str(result.inserted_id)

    # Auto-create a linked message so it appears in Notifications and links to the submission
    try:
        message_doc = {
            "patient_id": patient_id,
            "doctor_id": doctor_id,
            "sender": "system",
            "note_text": "Report received. Waiting for doctor review.",
            "submission_id": new_submission_id,
            "timestamp": datetime.utcnow(),
        }
        await messages_collection.insert_one(message_doc)
    except Exception as e:
        # Do not fail submission if message insertion fails
        print(f"[SUBMISSION] Linked message insert failed: {e}")

    return {"message": "Submission created", "submission_id": new_submission_id}


# Serve submission image from GridFS by submission id
@app.get("/submissions/{submission_id}/image")
async def get_submission_image(submission_id: str):
    # Find submission
    sub = None
    try:
        sub = await submissions_collection.find_one({"_id": ObjectId(submission_id)})
    except Exception:
        sub = await submissions_collection.find_one({"_id": submission_id})
    if not sub:
        raise HTTPException(status_code=404, detail="submission not found")

    file_id_str = sub.get("image_file_id")
    if not file_id_str:
        raise HTTPException(status_code=404, detail="submission has no image_file_id")

    try:
        gridout = await gridfs_bucket.open_download_stream(ObjectId(file_id_str))
    except Exception as e:
        raise HTTPException(status_code=404, detail=f"image not found: {e}")

    content = await gridout.read()
    meta = getattr(gridout, "metadata", {}) or {}
    ctype = meta.get("contentType") or "image/jpeg"
    filename = getattr(gridout, "filename", "image.jpg")
    return Response(content, media_type=ctype, headers={"Content-Disposition": f'inline; filename="{filename}"'})


# Serve image directly by GridFS file id
@app.get("/images/{file_id}")
async def get_image_by_file_id(file_id: str):
    try:
        gridout = await gridfs_bucket.open_download_stream(ObjectId(file_id))
    except Exception as e:
        raise HTTPException(status_code=404, detail=f"image not found: {e}")
    content = await gridout.read()
    meta = getattr(gridout, "metadata", {}) or {}
    ctype = meta.get("contentType") or "image/jpeg"
    filename = getattr(gridout, "filename", "image.jpg")
    return Response(content, media_type=ctype, headers={"Content-Disposition": f'inline; filename="{filename}"'})


# Conversation thread for a submission: patient report + doctor messages
@app.get("/submissions/{submission_id}/conversation")
async def get_submission_conversation(submission_id: str):
    """
    Returns a chronological 'chat' view of a submission.
    1. The Patient's Submission (formatted as the first message).
    2. All Doctor Notes/Messages linked to this submission.
    """
    try:
        sub_oid = ObjectId(submission_id)
        # 1. Fetch the Original Submission (The "First Message")
        submission = await submissions_collection.find_one({"_id": sub_oid})
        if not submission:
            raise HTTPException(status_code=404, detail="Submission not found")

        chat_thread = []

        # Convert Submission to a "Message" format
        patient_msg = {
            "id": str(submission["_id"]),
            "sender": "patient",
            "type": "report",  # Special type to render Image + Symptoms
            "content": submission.get("comments") or "",
            "image_file_id": submission.get("image_file_id"),
            "symptoms": {
                "Pain": submission.get("pain_scale"),
                "Redness": submission.get("redness"),
                "Watering": submission.get("watering"),
                "Vision": submission.get("vision_blur"),
                "Discharge": submission.get("discharge"),
            },
            "timestamp": submission.get("timestamp") or submission.get("created_at"),
        }
        chat_thread.append(serialize_doc(patient_msg))

        # 2. Fetch Linked Replies (Doctor Messages)
        # Compatibility: match messages that reference either submission_id or submission_ref_id
        query = {"$or": [{"submission_id": submission_id}, {"submission_ref_id": submission_id}]}
        cursor = messages_collection.find(query).sort("timestamp", 1)
        async for doc in cursor:
            doctor_msg = {
                "id": str(doc.get("_id")),
                "sender": doc.get("sender", "doctor"),
                "type": "text",
                "content": doc.get("note_text"),
                "timestamp": doc.get("timestamp") or doc.get("created_at"),
            }
            chat_thread.append(serialize_doc(doctor_msg))

        return chat_thread

    except Exception as e:
        print(f"Error fetching conversation: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/submissions/{submission_id}/reply")
async def simulate_doctor_reply(submission_id: str, text: str = Form(...)):
    """
    TEST ENDPOINT: Simulate a doctor sending a reply to a specific report.
    This guarantees the 'submission_id' link is created correctly.
    """
    # 1. Verify Submission exists
    try:
        sub = await submissions_collection.find_one({"_id": ObjectId(submission_id)})
    except Exception:
        sub = await submissions_collection.find_one({"_id": submission_id})

    if not sub:
        raise HTTPException(status_code=404, detail="Submission not found")

    # 2. Create the Reply Message
    reply_doc = {
        "patient_id": sub.get("patient_id"),
        "doctor_id": sub.get("doctor_id"),
        "sender": "doctor",       # Marks this as coming from the doctor
        "note_text": text,
        "submission_id": str(sub.get("_id")) if sub.get("_id") else submission_id,  # ensure string id
        "timestamp": datetime.utcnow(),
    }

    result = await messages_collection.insert_one(reply_doc)

    return {
        "status": "replied",
        "message_id": str(result.inserted_id),
        "text": text,
    }


@app.get("/patients/{patient_id}/messages")
async def get_messages_for_patient(patient_id: str):
    """Return messages for a patient, enriched with submission details.

    Compatibility: normalize `submission_ref_id` to `submission_id` so
    downstream always sees a consistent id to click through.
    """
    pipeline = [
        {"$match": {"patient_id": patient_id}},
        # Normalize field name: prefer submission_id, else submission_ref_id
        {
            "$addFields": {
                "submission_id": {"$ifNull": ["$submission_id", "$submission_ref_id"]}
            }
        },
        # Convert normalized submission_id to ObjectId for lookup
        {
            "$addFields": {
                "sub_oid": {
                    "$cond": [
                        {"$and": [{"$gt": ["$submission_id", None]}, {"$ne": ["$submission_id", ""]}]},
                        {"$toObjectId": "$submission_id"},
                        None,
                    ]
                }
            }
        },
        # Join with patient_submissions
        {
            "$lookup": {
                "from": "patient_submissions",
                "localField": "sub_oid",
                "foreignField": "_id",
                "as": "submission_details",
            }
        },
        {"$unwind": {"path": "$submission_details", "preserveNullAndEmptyArrays": True}},
        {"$sort": {"timestamp": -1}},
    ]

    messages: List[Dict[str, Any]] = []
    cursor = messages_collection.aggregate(pipeline)
    async for doc in cursor:
        messages.append(serialize_doc(doc))
    return messages

# utility: store token into fcm_tokens collection (unique)
@app.post("/patients/{patient_id}/fcm-token", status_code=201)
async def register_fcm_token(patient_id: str, payload: Dict[str, Any]):
    """
    payload JSON: { "token": "<fcm token>", "platform": "android|ios|web" (optional) }
    Stores token per patient in a dedicated collection.
    """
    token = payload.get("token") if isinstance(payload, dict) else None
    platform = payload.get("platform") if isinstance(payload, dict) else None
    if not token:
        raise HTTPException(status_code=400, detail="token required")
    now = datetime.utcnow().isoformat()
    doc = {
        "patient_id": patient_id,
        "token": token,
        "platform": platform,
        "created_at": now,
        "last_seen_at": now,
    }
    # upsert by token
    try:
        print(f"DEBUG: registering token for patient_id={patient_id} token={token[:20]}...")
    except Exception:
        print("DEBUG: registering token (could not format token)")
    await fcm_tokens_collection.update_one({"token": token}, {"$set": doc}, upsert=True)
    return {"status": "ok", "token": token}

async def _send_fcm_to_tokens(title: str, body: str, data: Dict[str, str], tokens: List[str]) -> Dict[str, Any]:
    """
    Send using firebase_admin.messaging.send_each_for_multicast (Required for v7.0+).
    """
    if not firebase_admin._apps:
        raise RuntimeError("Firebase admin not initialized")

    results_summary = {"success": 0, "failure": 0, "errors": []}

    async def _send_batch(batch):
        try:
            def sync_send():
                # 1. Create the MulticastMessage object
                message = messaging.MulticastMessage(
                    notification=messaging.Notification(title=title, body=body),
                    data=data or {},
                    tokens=batch,
                )
                # 2. Use the NEW method: send_each_for_multicast
                return messaging.send_each_for_multicast(message)

            # Run the sync function in a thread so it doesn't block the server
            resp = await asyncio.to_thread(sync_send)

            results_summary["success"] += resp.success_count
            results_summary["failure"] += resp.failure_count

            # 3. Collect errors
            for idx, resp_item in enumerate(resp.responses):
                if not resp_item.success:
                    results_summary["errors"].append({
                        "token": batch[idx],
                        "error": str(resp_item.exception)
                    })
        except Exception as e:
            results_summary["errors"].append({"batch_error": str(e)})

    # Batch processing (FCM limit is 500 tokens per batch)
    batch_size = 500
    tasks = []
    for i in range(0, len(tokens), batch_size):
        batch = tokens[i:i+batch_size]
        tasks.append(_send_batch(batch))

    await asyncio.gather(*tasks)
    return results_summary

async def _collect_target_tokens(recipients: Dict[str, Any]) -> List[str]:
    """
    recipients can be:
      { "all": true }  -> all tokens
      { "patients": ["id1","id2"] } -> tokens for those patients
      { "emails": ["a@b.com", "c@d.com"] } -> lookup IDs from emails, then tokens
      { "tokens": ["t1","t2"] } -> explicit tokens
    """
    if not recipients:
        return []

    # 1. Handle "All"
    if recipients.get("all"):
        cursor = fcm_tokens_collection.find({}, {"token": 1})
        tokens = []
        async for d in cursor:
            t = d.get("token")
            if t: tokens.append(t)
        return tokens

    # 2. Handle "Patients" (IDs)
    if recipients.get("patients"):
        patients = recipients.get("patients") or []
        cursor = fcm_tokens_collection.find({"patient_id": {"$in": patients}}, {"token": 1})
        tokens = []
        async for d in cursor:
            t = d.get("token")
            if t: tokens.append(t)
        return tokens

    # 3. Handle "Emails" (NEW LOGIC)
    if recipients.get("emails"):
        email_list = recipients.get("emails") or []
        # Find patient IDs that match these emails (checking both old schema and new schema paths)
        patient_cursor = patients_collection.find({
            "$or": [
                {"email": {"$in": email_list}},
                {"contactInfo.email": {"$in": email_list}},
                {"patientDetails.email": {"$in": email_list}}
            ]
        }, {"_id": 1})

        found_ids = []
        async for p in patient_cursor:
            found_ids.append(str(p["_id"]))

        if found_ids:
            # Now find tokens for these IDs
            token_cursor = fcm_tokens_collection.find({"patient_id": {"$in": found_ids}}, {"token": 1})
            tokens = []
            async for d in token_cursor:
                t = d.get("token")
                if t: tokens.append(t)
            return tokens
            token_cursor = fcm_tokens_collection.find({"patient_id": {"$in": found_ids}}, {"token": 1})
            tokens = []
            async for d in token_cursor:
                t = d.get("token")
                if t: tokens.append(t)
            return tokens

    # 4. Handle Explicit "Tokens"
    if recipients.get("tokens"):
        return list(recipients.get("tokens"))

    return []


@app.post('/debug/send-to-token')
async def debug_send_to_token(payload: Dict[str, Any]):
    """Development helper: send a notification to a single token and return send_result.

    Payload: { "token": "<fcm token>", "title": "...", "body": "...", "data": { ... } }
    """
    token = payload.get('token') if isinstance(payload, dict) else None
    title = payload.get('title') if isinstance(payload, dict) else ''
    body = payload.get('body') if isinstance(payload, dict) else ''
    data = payload.get('data') if isinstance(payload, dict) else {}
    if not token:
        raise HTTPException(status_code=400, detail='token required')
    if not firebase_admin._apps:
        raise HTTPException(status_code=500, detail='firebase admin not initialized')
    try:
        result = await _send_fcm_to_tokens(title, body, data or {}, [token])
        return {"status": "sent", "result": result}
    except Exception as ex:
        raise HTTPException(status_code=500, detail=str(ex))


@app.get('/debug/notifications/recent')
async def debug_recent_notifications(limit: int = 20):
    """Return recent notifications (dev helper)."""
    docs = []
    cursor = notifications_collection.find().sort('created_at', -1).limit(limit)
    async for d in cursor:
        docs.append(serialize_doc(d))
    return {"count": len(docs), "notifications": docs}

# endpoint: create notification and auto-send
@app.post("/notifications", status_code=201)
async def create_notification(payload: Dict[str, Any]):
    """
    Insert notification doc and immediately send via FCM.
    Expected payload fields (example):
    {
      "doctor_id": "...",
      "doctor_name": "...",
      "title": "Title",
      "message": "Body",
      "recipients": { "all": true } or { "patients": ["id"] } or { "tokens": ["..."] },
      "image_file_ids": []
    }
    """
    doc = deepcopy(payload)
    doc.setdefault("created_at", datetime.utcnow().isoformat())
    doc.setdefault("sent", False)
    doc.setdefault("delivery", {})
    result = await notifications_collection.insert_one(doc)
    notif_id = str(result.inserted_id)
    # perform sending in background (do not block long)
    async def _send_and_update():
        try:
            recipients = doc.get("recipients", {})
            tokens = await _collect_target_tokens(recipients)
            # debug: log recipient resolution so we can diagnose missing tokens
            try:
                print(f"DEBUG: notification {notif_id} recipients={recipients} -> tokens_found={len(tokens)}")
            except Exception:
                # avoid logging errors from formatting
                print("DEBUG: notification recipients resolved (could not format details)")
            if not tokens:
                await notifications_collection.update_one({"_id": ObjectId(notif_id)}, {"$set": {"sent": False, "sent_at": None, "delivery": {"error": "no_tokens"}}})
                return
            data_payload = {"type": "doctor_notification", "notification_id": notif_id}
            send_result = await _send_fcm_to_tokens(doc.get("title",""), doc.get("message",""), data_payload, tokens)
            # debug: surface send result in server logs for quick diagnosis
            try:
                print(f"DEBUG: notification {notif_id} send_result={send_result}")
            except Exception:
                print("DEBUG: notification send_result available (could not format)")
            # prune tokens with unrecoverable errors (example contains "NotRegistered" or "InvalidArgument")
            to_remove = []
            for err in send_result.get("errors", []):
                e = err.get("error","")
                token = err.get("token")
                if token and ("NotRegistered" in e or "invalid" in e.lower() or "registration-token-not-registered" in e):
                    to_remove.append(token)
            if to_remove:
                await fcm_tokens_collection.delete_many({"token": {"$in": to_remove}})
            await notifications_collection.update_one({"_id": ObjectId(notif_id)}, {"$set": {"sent": True, "sent_at": datetime.utcnow().isoformat(), "delivery": send_result}})
        except Exception as ex:
            await notifications_collection.update_one({"_id": ObjectId(notif_id)}, {"$set": {"sent": False, "delivery": {"error": str(ex)}}})
    # schedule background task
    asyncio.create_task(_send_and_update())
    return {"status": "queued", "notification_id": notif_id}


@app.post("/patients/{patient_id}/schedule-meds", status_code=201)
async def schedule_patient_medicine_notifications(patient_id: str):
    """
    Generates notification and dose records based on the LATEST prescription found.
    """
    # 1. Load Patient
    try:
        p = await patients_collection.find_one({"_id": ObjectId(patient_id)})
    except:
        p = await patients_collection.find_one({"_id": patient_id})

    if not p:
        raise HTTPException(status_code=404, detail="patient not found")

    # 2. Find Prescription Items using Robust Finder
    items = _find_latest_prescription_items(p)

    # Fallback: check simple "medicines" list from Doctor App
    if not items:
        simple_meds = p.get("medicines") or []
        if simple_meds:
            for entry in simple_meds:
                text = entry.get("value") if isinstance(entry, dict) else str(entry)
                if text:
                    items.append({"name": text, "frequency": text, "duration": "7 days"})

    if not items:
        # Return success but 0 items to avoid app crashing on 400
        return {"status": "no_prescription_found", "count": 0}

    # 3. Determine Start Date (IST) - Use Now
    start_dt = datetime.now(IST)
    created_docs = []

    # 4. Iterate Items and Schedule
    for item in items:
        med_name = item.get("name") or item.get("drug") or item.get("medicine") or "Medicine"
        freq_str = str(item.get("frequency") or "")
        dur_str = str(item.get("duration") or "7 days")

        # Parse logic
        times_per_day = _parse_times_per_day_from_text(freq_str)

        # LOGIC CHANGE START
        if times_per_day in _DAYSCHEDULES:
            times_list = _DAYSCHEDULES[times_per_day]
        else:
            # Dynamic generation for high frequency (e.g. 8 times)
            # Spread them out between 6:00 AM and 10:00 PM (16 hours)
            start_hour = 6
            end_hour = 22
            window = end_hour - start_hour

            # Prevent division by zero
            step = window / max(1, (times_per_day - 1)) if times_per_day > 1 else 0

            times_list = []
            for i in range(times_per_day):
                h = int(start_hour + (i * step))
                # clamp hour to 23 max just in case
                h = min(h, 23)
                times_list.append(time(h, 0, tzinfo=IST))
        # LOGIC CHANGE END

        duration_days = _parse_duration_days(dur_str, default_days=7)

        # Generate DateTimes
        send_datetimes = _make_send_datetimes_for_duration(times_list, start_dt, duration_days)

        for send_at in send_datetimes:
            # Create Notification
            dose_label = _dose_label_for_time(datetime.fromisoformat(send_at).time())
            title = f"Medicine: {med_name}"
            message = f"Time to take your {dose_label} dose ({med_name})."

            notif_doc = {
                "patient_id": patient_id,
                "title": title,
                "message": message,
                "recipients": {"patients": [patient_id]},
                "send_at": send_at,
                "sent": False,
                "created_at": datetime.utcnow().isoformat(),
                "metadata": {"type": "dose", "medicine": med_name}
            }
            res = await notifications_collection.insert_one(notif_doc)
            created_docs.append(str(res.inserted_id))

            # Upsert Dose Record
            try:
                dt_obj = datetime.fromisoformat(send_at)
                dose_filter = {
                    "patient_id": patient_id,
                    "medicine_name": med_name,
                    "date": dt_obj.date().isoformat(),
                    "dose_label": dose_label
                }
                dose_doc = {
                    **dose_filter,
                    "scheduled_time": dt_obj.strftime("%H:%M"),
                    "scheduled_iso": send_at,
                    "taken": False,
                    "notified": False,
                    "created_at": datetime.utcnow().isoformat(),
                    "notification_id": str(res.inserted_id)
                }
                await medicine_doses_collection.update_one(dose_filter, {"$setOnInsert": dose_doc}, upsert=True)
            except Exception as e:
                print(f"[SCHEDULE] Error creating dose record: {e}")

    return {
        "status": "scheduled",
        "count": len(created_docs),
        "items_processed": len(items)
    }


# ---------------------------------------------------------
# FOLLOW-UP SCHEDULING ENDPOINT
# ---------------------------------------------------------
@app.post("/patients/{patient_id}/schedule-followups", status_code=201)
async def schedule_followup_notifications(patient_id: str, surgery_date: Optional[str] = None):
    """
    Schedules 1-day, 1-week, and 1-month follow-up notifications.
    If surgery_date is not provided, it uses the current time (IST).
    """
    # 1. Determine the baseline (Surgery Date)
    if surgery_date:
        try:
            base_dt = datetime.fromisoformat(surgery_date.replace("Z", "+00:00"))
        except Exception:
            raise HTTPException(status_code=400, detail="Invalid surgery_date format")
    else:
        base_dt = datetime.now(IST)

    # 2. Define the milestones
    milestones = [
        {"label": "1-Day Post-Op", "delta": timedelta(days=1), "msg": "How is your eye feeling today?"},
        {"label": "1-Week Follow-up", "delta": timedelta(days=7), "msg": "It's time for your 1-week checkup!"},
        {"label": "1-Month Progress", "delta": timedelta(days=30), "msg": "Time for your monthly vision check."}
    ]

    created_ids = []
    for m in milestones:
        # Schedule for 9:00 AM on the milestone day
        try:
            scheduled_time = (base_dt + m["delta"]).replace(hour=9, minute=0, second=0, microsecond=0)
        except Exception:
            target_dt = base_dt + m["delta"]
            scheduled_time = datetime(target_dt.year, target_dt.month, target_dt.day, 9, 0, 0, tzinfo=target_dt.tzinfo)

        notif_doc = {
            "patient_id": patient_id,
            "title": f"Appointment Reminder: {m['label']}",
            "message": m["msg"],
            "recipients": {"patients": [patient_id]},
            "send_at": scheduled_time.isoformat(),
            "sent": False,
            "created_at": datetime.utcnow().isoformat(),
            "metadata": {"type": "appointment_reminder", "milestone": m["label"]}
        }

        res = await notifications_collection.insert_one(notif_doc)
        created_ids.append(str(res.inserted_id))

    return {
        "status": "scheduled",
        "milestones_created": len(created_ids),
        "surgery_date": base_dt.isoformat()
    }


# --- Dose endpoints ---
@app.get("/patients/{patient_id}/today-doses")
async def get_today_doses(patient_id: str):
    """
    Return today's dose slots. Lazily creates if missing.
    """
    today_ist = datetime.now(IST).date().isoformat()

    # 1. Fetch Existing Doses
    cursor = medicine_doses_collection.find({"patient_id": patient_id, "date": today_ist}).sort("scheduled_iso", 1)
    doses = [serialize_doc(d) async for d in cursor]

    # 2. Sync/Lazy Create (Always check for new medicines in prescription)
    try:
        p = await patients_collection.find_one({"_id": ObjectId(patient_id)})
    except:
        p = await patients_collection.find_one({"_id": patient_id})

    if not p:
        return doses # Return what we have if patient not found

    items = _find_latest_prescription_items(p)

    # Fallback to simple list
    if not items:
        simple_meds = p.get("medicines") or []
        for entry in simple_meds:
            text = entry.get("value") if isinstance(entry, dict) else str(entry)
            if text:
                items.append({"name": text, "frequency": text, "duration": ""})

    if not items:
        return doses

    # Generate/Update TODAY'S slots (using upsert to avoid duplicates)
    new_doses_added = False
    for item in items:
        med_name = item.get("name") or item.get("drug") or item.get("medicine") or "Medicine"
        freq_str = str(item.get("frequency") or item.get("name") or "")

        times_per_day = _parse_times_per_day_from_text(freq_str)
        times_list = _DAYSCHEDULES.get(times_per_day, _DAYSCHEDULES[1])

        for t in times_list:
            dt_ist = datetime.combine(datetime.now(IST).date(), t, tzinfo=IST)
            label = _dose_label_for_time(dt_ist.timetz())

            dose_filter = {
                "patient_id": patient_id,
                "medicine_name": med_name,
                "date": today_ist,
                "dose_label": label
            }

            dose_doc = {
                **dose_filter,
                "scheduled_time": dt_ist.strftime("%H:%M"),
                "scheduled_iso": dt_ist.isoformat(),
                "taken": False,
                "notified": False,
                "created_at": datetime.utcnow().isoformat(),
            }

            await medicine_doses_collection.update_one(dose_filter, {"$setOnInsert": dose_doc}, upsert=True)

    # Re-fetch
    cursor = medicine_doses_collection.find({"patient_id": patient_id, "date": today_ist}).sort("scheduled_iso", 1)
    return [serialize_doc(d) async for d in cursor]

# Backward-compat alias for old client path
@app.get("/patients/{patient_id}/doses/today")
async def get_today_doses_compat(patient_id: str):
    """Alias to support legacy client calls to /doses/today."""
    return await get_today_doses(patient_id)


@app.post("/patients/{patient_id}/doses/{dose_id}/take")
async def take_dose(patient_id: str, dose_id: str):
    """Mark a specific dose as taken. Idempotent.
    Also writes to adherence_collection for analytics.
    """
    try:
        oid = ObjectId(dose_id)
    except Exception:
        raise HTTPException(status_code=400, detail="invalid dose_id")

    dose = await medicine_doses_collection.find_one({"_id": oid, "patient_id": patient_id})
    if not dose:
        raise HTTPException(status_code=404, detail="dose not found")

    if dose.get("taken"):
        # Already taken: return success without changes
        return {"status": "already_taken", "dose_id": dose_id}

    now_iso = datetime.utcnow().isoformat()
    await medicine_doses_collection.update_one({"_id": oid}, {"$set": {"taken": True, "taken_at": now_iso}})

    # Also record adherence for analytics
    try:
        doc = {
            "patient_id": patient_id,
            "patient_name": None,
            "doctor_id": dose.get("doctor_id"),
            "doctor_name": None,
            "medicine": dose.get("medicine_name"),
            "taken": 1,
            "created_at": now_iso,
        }
        await adherence_collection.insert_one(doc)
    except Exception:
        pass

    return {"status": "taken", "dose_id": dose_id}


@app.get("/patients/{patient_id}/next-dose")
async def next_dose(patient_id: str):
    """Return next upcoming untaken dose slot for a patient (IST)."""
    now_ist = datetime.now(IST).isoformat()
    cursor = medicine_doses_collection.find({
        "patient_id": patient_id,
        "taken": False,
        "scheduled_iso": {"$gte": now_ist},
    }).sort("scheduled_iso", 1).limit(1)
    doses = [serialize_doc(d) async for d in cursor]
    if not doses:
        return {"next": None}
    d = doses[0]
    return {"next": d}


# --- Debug endpoints (safe for development only) ---
@app.get('/debug/firebase')
async def debug_firebase():
    """Return firebase-admin initialization state for quick checks."""
    initialized = bool(firebase_admin._apps) or FIREBASE_INITIALIZED
    app_names = list(firebase_admin._apps.keys()) if bool(firebase_admin._apps) else []
    return {"firebase_initialized": initialized, "apps": app_names, "last_error": LAST_FIREBASE_ERROR}


@app.get('/debug/doctor-backend')
async def debug_doctor_backend():
    """Return the configured doctor backend URL and whether forwarding is enabled."""
    return {"doctor_backend_url": DOCTOR_BACKEND_URL or None, "forwarding_enabled": bool(DOCTOR_BACKEND_URL)}


@app.get('/debug/patient/{patient_id}/tokens')
async def debug_patient_tokens(patient_id: str):
    """Return tokens stored for a patient (development helper)."""
    tokens = []
    cursor = fcm_tokens_collection.find({"patient_id": patient_id})
    async for d in cursor:
        tokens.append({"token": d.get("token"), "platform": d.get("platform"), "last_seen_at": d.get("last_seen_at")})
    return {"patient_id": patient_id, "count": len(tokens), "tokens": tokens}


@app.post('/tokens', status_code=201)
async def push_token(payload: Dict[str, Any]):
    """Generic endpoint to push an FCM token into MongoDB.

    Accepts JSON: { "patient_id": "<id>", "token": "<fcm token>", "platform": "android|ios|web" }
    This is a convenience endpoint for clients that can't call the patient-scoped route.
    """
    if not isinstance(payload, dict):
        raise HTTPException(status_code=400, detail="invalid payload")
    patient_id = payload.get("patient_id")
    token = payload.get("token")
    platform = payload.get("platform")
    if not patient_id or not token:
        raise HTTPException(status_code=400, detail="patient_id and token required")
    now = datetime.utcnow().isoformat()
    doc = {
        "patient_id": patient_id,
        "token": token,
        "platform": platform,
        "created_at": now,
        "last_seen_at": now,
    }
    try:
        print(f"DEBUG: push_token patient_id={patient_id} token={token[:20]}...")
    except Exception:
        print("DEBUG: push_token (could not format token)")
    await fcm_tokens_collection.update_one({"token": token}, {"$set": doc}, upsert=True)
    return {"status": "ok", "token": token}


@app.post('/adherence', status_code=201)
async def record_adherence(payload: Dict[str, Any]):
    """Record medicine adherence for a patient.

    Expected JSON:
    {
      "patient_id": "...",
      "patient_name": "...",
      "doctor_id": "...",
      "doctor_name": "...",
      "medicine": "Paracetamol",
      "taken": 1  # 1 = taken, 0 = not taken
    }
    """
    if not isinstance(payload, dict):
        raise HTTPException(status_code=400, detail="invalid payload")
    patient_id = payload.get("patient_id")
    medicine = payload.get("medicine")
    taken = payload.get("taken")
    if not patient_id or medicine is None or taken is None:
        raise HTTPException(status_code=400, detail="patient_id, medicine and taken are required")
    now = datetime.utcnow().isoformat()
    doc = {
        "patient_id": patient_id,
        "patient_name": payload.get("patient_name"),
        "doctor_id": payload.get("doctor_id"),
        "doctor_name": payload.get("doctor_name"),
        "medicine": medicine,
        "taken": int(taken),
        "created_at": now,
    }
    res = await adherence_collection.insert_one(doc)
    return {"status": "ok", "id": str(res.inserted_id)}


@app.post('/vision-tests', status_code=201)
async def create_vision_test(payload: Dict[str, Any]):
    """Accept vision test results JSON and store in `visiontests` collection.

    Expected JSON shape:
    {
      "patient_id": "...",
      "patient_name": "...",
      "timestamp": "2025-11-28T...",
      "logMAR_levels": [0.0, 0.1, ...],
      "sessions": [ {"session":0, "level":0.0, "correct": true}, ... ]
    }
    """
    if not isinstance(payload, dict):
        raise HTTPException(status_code=400, detail='invalid payload')
    patient_id = payload.get('patient_id')
    patient_name = payload.get('patient_name')
    if not patient_id or not patient_name:
        raise HTTPException(status_code=400, detail='patient_id and patient_name required')

    doc = {
        'patient_id': patient_id,
        'patient_name': patient_name,
        'timestamp': payload.get('timestamp') or datetime.utcnow().isoformat(),
        'logMAR_levels': payload.get('logMAR_levels') or [],
        'sessions': payload.get('sessions') or [],
        'final_acuity': payload.get('final_acuity'),
        'created_at': datetime.utcnow().isoformat(),
    }
    result = await visiontests_collection.insert_one(doc)
    return {'status': 'created', 'vision_test_id': str(result.inserted_id)}


# ---------------------------------------------------------
# VISION & AMSLER ENDPOINTS
# ---------------------------------------------------------

@app.post("/vision/amsler", status_code=201)
async def submit_amsler_test(
    patient_id: str = Form(...),
    eye_side: str = Form(...),  # "Left", "Right", or "Both"
    notes: Optional[str] = Form(None),
    image: UploadFile = File(...),
):
    """
    Uploads the user's drawing on the Amsler Grid.
    """
    # 1. Upload the Drawing Image
    file_id = await gridfs_bucket.upload_from_stream(
        image.filename,
        image.file,
        metadata={"contentType": image.content_type}
    )

    # 2. Create the Record
    test_doc = {
        "patient_id": patient_id,
        "test_type": "Amsler Grid",
        "eye_side": eye_side,
        "image_file_id": str(file_id),
        "notes": notes,
        "timestamp": datetime.utcnow()
    }

    # 3. Insert into specific amsler collection
    res = await amsler_collection.insert_one(test_doc)

    return {
        "status": "success",
        "test_id": str(res.inserted_id),
        "message": "Amsler test saved"
    }


@app.get("/vision/patient/{patient_id}")
async def get_vision_history(patient_id: str):
    """
    Fetches history of vision tests (Amsler AND Tumbling E) for the Vision Screen list.
    Merges both into a unified format with common fields.
    """
    history: List[Dict[str, Any]] = []

    # 1. Fetch Amsler Tests
    amsler_cursor = amsler_collection.find({"patient_id": patient_id}).sort("timestamp", -1)
    async for doc in amsler_cursor:
        # Convert to unified format
        unified = {
            "id": str(doc.get("_id")),
            "test_type": "Amsler Grid",
            "timestamp": doc.get("timestamp"),
            "patient_id": doc.get("patient_id"),
            "eye_side": doc.get("eye_side", "Both"),
            "notes": doc.get("notes", ""),
            "image_file_id": doc.get("image_file_id"),
            "final_acuity": None,
        }
        history.append(serialize_doc(unified))

    # 2. Fetch Tumbling E Tests (visiontests_collection)
    vision_cursor = visiontests_collection.find({"patient_id": patient_id}).sort("timestamp", -1)
    async for doc in vision_cursor:
        # Convert to unified format
        unified = {
            "id": str(doc.get("_id")),
            "test_type": "Tumbling E",
            "timestamp": doc.get("timestamp"),
            "patient_id": doc.get("patient_id"),
            "patient_name": doc.get("patient_name"),
            "eye_side": "Both",
            "notes": "",
            "final_acuity": doc.get("final_acuity"), # Include final_acuity from Tumbling E
            "logMAR_levels": doc.get("logMAR_levels", []),
            "sessions": doc.get("sessions", []),
        }
        history.append(serialize_doc(unified))

    # 3. Sort combined list by newest first
    try:
        # After serialize_doc, timestamp is a string (ISO format)
        history.sort(key=lambda x: x.get("timestamp") or "", reverse=True)
    except Exception:
        pass

    return history


@app.get('/adherence/patient/{patient_id}')
async def get_adherence_for_patient(patient_id: str, limit: int = 200):
    docs = []
    cursor = adherence_collection.find({"patient_id": patient_id}).sort('created_at', -1).limit(limit)
    async for d in cursor:
        docs.append(serialize_doc(d))
    return {"patient_id": patient_id, "count": len(docs), "adherence": docs}


# ============ GRAPH AGGREGATION ENDPOINT ============

@app.get("/adherence/graph")
async def get_adherence_graph(
    patient_id: str,
    view_mode: str,  # "day", "week", "medicine"
    range_type: str = "week" # "today", "week", "month"
):
    """
    Single Endpoint for All Graphs.
    Returns: { "x_axis": [...labels], "y_axis": [...counts], "title": "..." }
    """
    now = datetime.now(IST)
    today_str = now.date().isoformat()

    x_axis = []
    y_axis = []
    title = ""

    # --- 1. DAY VIEW (Time of Day) ---
    # Shows today's performance breakdown
    if view_mode == "day":
        title = "Today's Intake"
        # Fixed Categories
        categories = ["Morning", "Afternoon", "Evening", "Bedtime"]
        x_axis = categories

        # Initialize counts
        counts = {cat: 0 for cat in categories}

        # Query doses for TODAY
        cursor = medicine_doses_collection.find({
            "patient_id": patient_id,
            "date": today_str,
            "taken": True
        })

        async for dose in cursor:
            label = dose.get("dose_label", "Morning") # Default to Morning if missing
            # Normalize labels
            if "Morning" in label: k = "Morning"
            elif "Afternoon" in label: k = "Afternoon"
            elif "Evening" in label: k = "Evening"
            elif "Night" in label or "Bedtime" in label: k = "Bedtime"
            else: k = "Morning"

            if k in counts:
                counts[k] += 1

        y_axis = [counts[c] for c in categories]

    # --- 2. WEEK VIEW (Last 7 Days) ---
    # Shows total doses taken per day
    elif view_mode == "week":
        title = "Weekly Adherence"
        # Generate last 7 days labels (e.g., "Mon", "Tue")
        dates = []
        date_map = {} # "YYYY-MM-DD" -> index

        for i in range(6, -1, -1):
            d = now - timedelta(days=i)
            d_str = d.date().isoformat()
            d_label = WEEKDAY_LABELS[d.weekday()] # Mon, Tue...
            dates.append(d_str)
            x_axis.append(d_label)
            date_map[d_str] = len(x_axis) - 1
            y_axis.append(0) # Init 0

        # Query taken doses in date range
        start_date = dates[0]
        end_date = dates[-1]

        cursor = medicine_doses_collection.find({
            "patient_id": patient_id,
            "date": {"$gte": start_date, "$lte": end_date},
            "taken": True
        })

        async for dose in cursor:
            d_str = dose.get("date")
            if d_str in date_map:
                idx = date_map[d_str]
                y_axis[idx] += 1

    # --- 3. MEDICINE VIEW (Performance by Med) ---
    # Shows total taken count for each medicine (Past 30 days default)
    elif view_mode == "medicine":
        title = "Medicine Performance (Last 30 Days)"

        # Query taken doses
        start_date = (now - timedelta(days=30)).date().isoformat()

        cursor = medicine_doses_collection.find({
            "patient_id": patient_id,
            "date": {"$gte": start_date},
            "taken": True
        })

        med_counts = {}
        async for dose in cursor:
            name = dose.get("medicine_name", "Unknown")
            # Clean up name (remove dosage info if needed, or keep full)
            short_name = name.split(" ")[0] # Simple: just first word
            med_counts[short_name] = med_counts.get(short_name, 0) + 1

        # Sort by count desc
        sorted_meds = sorted(med_counts.items(), key=lambda item: item[1], reverse=True)

        x_axis = [m[0] for m in sorted_meds]
        y_axis = [m[1] for m in sorted_meds]

        if not x_axis:
            x_axis = ["No Data"]
            y_axis = [0]

    return {
        "title": title,
        "x_axis": x_axis,
        "y_axis": y_axis,
        "view_mode": view_mode
    }

# manual send endpoint for existing notification document
@app.post("/notifications/{notif_id}/send")
async def send_existing_notification(notif_id: str):
    n = await notifications_collection.find_one({"_id": ObjectId(notif_id)})
    if not n:
        raise HTTPException(status_code=404, detail="notification not found")
    # If a doctor backend URL is configured, forward this send request to it.
    if DOCTOR_BACKEND_URL:
        forward_url = DOCTOR_BACKEND_URL.rstrip('/') + f'/notifications/{notif_id}/send'
        try:
            # Convert ObjectId to string for JSON serialization
            n_serializable = deepcopy(n)
            if "_id" in n_serializable:
                n_serializable["_id"] = str(n_serializable["_id"])
            async with httpx.AsyncClient(timeout=15.0) as client:
                resp = await client.post(forward_url, json=n_serializable)
                body_text = None
                try:
                    body_text = resp.json()
                except Exception:
                    body_text = resp.text
                delivery = {"forwarded_to_doctor": True, "status_code": resp.status_code, "response": body_text}
                sent_flag = resp.status_code in (200, 201)
                await notifications_collection.update_one({"_id": ObjectId(notif_id)}, {"$set": {"sent": sent_flag, "sent_at": datetime.utcnow().isoformat() if sent_flag else None, "delivery": delivery}})
                return {"status": "forwarded", "doctor_status": resp.status_code, "doctor_response": body_text}
        except Exception as fe:
            await notifications_collection.update_one({"_id": ObjectId(notif_id)}, {"$set": {"sent": False, "delivery": {"error": f"forward_failed: {fe}"}}})
            raise HTTPException(status_code=500, detail=f"forward_failed: {fe}")

    # Fallback to local send if doctor backend not configured
    recipients = n.get("recipients", {})
    tokens = await _collect_target_tokens(recipients)
    if not tokens:
        raise HTTPException(status_code=400, detail="no tokens found for recipients")
    try:
        data_payload = {"type": "doctor_notification", "notification_id": notif_id}
        send_result = await _send_fcm_to_tokens(n.get("title", ""), n.get("message", ""), data_payload, tokens)
        # remove bad tokens
        to_remove = []
        for err in send_result.get("errors", []):
            e = err.get("error", "")
            token = err.get("token")
            if token and ("NotRegistered" in e or "invalid" in e.lower() or "registration-token-not-registered" in e):
                to_remove.append(token)
        if to_remove:
            await fcm_tokens_collection.delete_many({"token": {"$in": to_remove}})
        await notifications_collection.update_one({"_id": ObjectId(notif_id)}, {"$set": {"sent": True, "sent_at": datetime.utcnow().isoformat(), "delivery": send_result}})
        return {"status": "sent", "result": send_result}
    except Exception as ex:
        await notifications_collection.update_one({"_id": ObjectId(notif_id)}, {"$set": {"sent": False, "delivery": {"error": str(ex)}}})
        raise HTTPException(status_code=500, detail=str(ex))


# ==========================================
# DIAGNOSTIC ENDPOINTS (DEVELOPMENT ONLY)
# ==========================================

@app.get('/debug/find-email/{email}')
async def debug_find_email(email: str):
    """
    Search entire patients collection for a given email string.
    Scans ALL documents and returns the structure where email is found.
    Used to diagnose login failures due to unknown email field locations.
    """
    print(f"[DEBUG_FIND_EMAIL] Searching for: {email}")

    # Get all patients and search programmatically
    all_patients = []
    cursor = patients_collection.find()
    async for p in cursor:
        all_patients.append(p)

    print(f"[DEBUG_FIND_EMAIL] Total patients in DB: {len(all_patients)}")

    found_in = []
    for patient in all_patients:
        # Convert to JSON string and search
        patient_str = str(patient).lower()
        email_lower = email.lower()

        if email_lower in patient_str:
            # Found it! Now figure out which field
            patient_id = str(patient.get("_id", "unknown"))
            name = patient.get("name", patient.get("patientDetails", {}).get("name", "Unknown"))

            # Check each known field
            locations = []
            if patient.get("email", "").lower() == email_lower:
                locations.append("email")
            if patient.get("contactInfo", {}).get("email", "").lower() == email_lower:
                locations.append("contactInfo.email")
            if patient.get("patientDetails", {}).get("email", "").lower() == email_lower:
                locations.append("patientDetails.email")

            found_in.append({
                "patient_id": patient_id,
                "name": name,
                "found_in_fields": locations,
                "full_patient_doc": serialize_doc(patient) if len(all_patients) < 10 else "..."  # Don't return huge docs
            })

    return {
        "search_email": email,
        "total_patients_in_db": len(all_patients),
        "matches_found": len(found_in),
        "matches": found_in
    }


# ==========================================
# BACKGROUND NOTIFICATION DISPATCHER

# ==========================================

async def notification_dispatcher_loop():
    """
    Background task that automatically sends medicine reminders at their scheduled time.
    Runs every 60 seconds to check for due notifications.
    """
    print("[DISPATCHER] Starting notification dispatcher background task...")
    while True:
        try:
            await asyncio.sleep(60)  # Check every 60 seconds
            now = datetime.now(IST)
            now_str = now.isoformat()  # Convert to ISO string for comparison

            # First: check dose slots that are due and not yet notified
            try:
                due_doses = await medicine_doses_collection.find({
                    "scheduled_iso": {"$lte": now_str},
                    "taken": False,
                    "notified": False,
                }).to_list(None)
                for dose in due_doses:
                    patient_id = dose.get("patient_id")
                    med_name = dose.get("medicine_name") or "Medicine"
                    label = dose.get("dose_label") or "Dose"
                    title = f"Time to take: {med_name}"
                    message = f"{label} dose now"
                    notif_doc = {
                        "patient_id": patient_id,
                        "title": title,
                        "message": message,
                        "recipients": {"patients": [patient_id]},
                        "send_at": now_str,
                        "sent": False,
                        "created_at": datetime.utcnow().isoformat(),
                        "metadata": {"type": "dose", "dose_id": str(dose.get("_id"))},
                    }
                    nres = await notifications_collection.insert_one(notif_doc)

                    tokens = await _collect_target_tokens({"patients": [patient_id]})
                    if tokens:
                        data_payload = {"type": "medicine_dose", "dose_id": str(dose.get("_id")), "notification_id": str(nres.inserted_id)}
                        result = await _send_fcm_to_tokens(title, message, data_payload, tokens)
                        await notifications_collection.update_one(
                            {"_id": nres.inserted_id},
                            {"$set": {"sent": True, "sent_at": datetime.utcnow().isoformat(), "delivery": result}}
                        )
                    # mark dose as notified regardless to avoid spamming
                    await medicine_doses_collection.update_one({"_id": dose.get("_id")}, {"$set": {"notified": True, "notified_at": datetime.utcnow().isoformat()}})
            except Exception as e:
                print(f"[DISPATCHER] [ERROR] Dose scan error: {e}")

            # Find notifications that are due (send_at <= now) and not yet sent
            # Note: send_at is stored as string in ISO format
            due_notifications = await notifications_collection.find({
                "send_at": {"$lte": now_str},
                "sent": False
            }).to_list(None)

            for notif in due_notifications:
                try:
                    notif_id = notif["_id"]
                    recipients = notif.get("recipients", {})

                    # Collect FCM tokens for recipients
                    tokens = await _collect_target_tokens(recipients)

                    if tokens:
                        # Send via FCM
                        data_payload = {
                            "type": "medicine_reminder",
                            "notification_id": str(notif_id)
                        }
                        result = await _send_fcm_to_tokens(
                            notif.get("title", ""),
                            notif.get("message", ""),
                            data_payload,
                            tokens
                        )

                        # Remove bad tokens from database
                        to_remove = []
                        for err in result.get("errors", []):
                            e = err.get("error", "")
                            token = err.get("token")
                            if token and ("NotRegistered" in e or "invalid" in e.lower() or "registration-token-not-registered" in e):
                                to_remove.append(token)
                        if to_remove:
                            await fcm_tokens_collection.delete_many({"token": {"$in": to_remove}})

                        # Mark notification as sent
                        await notifications_collection.update_one(
                            {"_id": notif_id},
                            {"$set": {
                                "sent": True,
                                "sent_at": datetime.utcnow().isoformat(),
                                "delivery": result
                            }}
                        )

                        print(f"[DISPATCHER] [SENT] Notification {notif_id}: {notif.get('title', '')[:50]}")
                    else:
                        print(f"[DISPATCHER] [WARN] No tokens found for notification {notif_id}")

                except Exception as e:
                    print(f"[DISPATCHER] [ERROR] Error sending notification: {e}")

        except Exception as e:
            print(f"[DISPATCHER] [ERROR] Background task error: {e}")
            await asyncio.sleep(10)


# ==========================================
# WEEKLY ADHERENCE STATS ENDPOINT
# ==========================================

def _infer_expected_daily_meds_from_prescription(prescription: Dict[str, Any]) -> int:
    """Count distinct medicines expected daily based on prescription items.
    Frequency keywords interpreted as daily presence (OD/BD/TID/QID -> present).
    """
    if not isinstance(prescription, dict):
        return 0
    items = prescription.get("items") or []
    names = set()
    for it in items:
        if not isinstance(it, dict):
            # allow simple strings
            if isinstance(it, str) and it.strip():
                names.add(it.strip())
            continue
        name = (it.get("name") or it.get("drug") or it.get("medicine") or "").strip()
        freq = str(it.get("frequency") or "").lower()
        # treat any frequency indicating daily regimen as expected
        daily = False
        if any(k in freq for k in ["od", "once", "daily"]):
            daily = True
        if any(k in freq for k in ["bd", "twice", "2 times"]):
            daily = True
        if any(k in freq for k in ["tid", "thrice", "3 times"]):
            daily = True
        if any(k in freq for k in ["qid", "four", "4 times"]):
            daily = True
        # if frequency missing, assume daily presence
        if not freq:
            daily = True
        if daily and name:
            names.add(name)
    return len(names)


def _date_ist(dt: datetime) -> datetime:
    return dt.astimezone(IST)


@app.get("/adherence/stats/week/{patient_id}")
async def adherence_stats_week(patient_id: str, start: Optional[str] = None):
    """Return 7-day adherence stats (IST-based) for a patient.
    - For each day: taken = distinct medicines with taken==1 in adherence.
    - expected per day = distinct daily medicines from prescription.
    """
    # determine 7-day window
    now_ist = datetime.now(IST)
    if start:
        try:
            start_dt = datetime.fromisoformat(start)
            if start_dt.tzinfo is None:
                start_dt = start_dt.replace(tzinfo=IST)
            start_dt = start_dt.astimezone(IST)
        except Exception:
            raise HTTPException(status_code=400, detail="invalid start date")
    else:
        start_dt = _date_ist(now_ist).replace(hour=0, minute=0, second=0, microsecond=0) - timedelta(days=6)

    # end inclusive: start + 6 days
    days = [start_dt.date() + timedelta(days=i) for i in range(7)]

    # fetch adherence docs in window
    start_iso = datetime.combine(days[0], time(0,0), tzinfo=IST).isoformat()
    end_iso = datetime.combine(days[-1], time(23,59,59,999000), tzinfo=IST).isoformat()
    cursor = adherence_collection.find({
        "patient_id": patient_id,
        "$or": [
            {"created_at": {"$gte": start_iso, "$lte": end_iso}},
            {"timestamp": {"$gte": start_iso, "$lte": end_iso}},
        ]
    })

    per_day_taken: Dict[str, set] = {d.isoformat(): set() for d in days}

    async for doc in cursor:
        created = doc.get("created_at") or doc.get("timestamp")
        try:
            dt = datetime.fromisoformat(str(created).replace("Z", "+00:00"))
        except Exception:
            continue
        dt_ist = dt.astimezone(IST) if dt.tzinfo else dt.replace(tzinfo=IST)
        day_key = dt_ist.date().isoformat()
        taken = doc.get("taken")
        med = str(doc.get("medicine") or "").strip()
        if taken == 1 and med:
            if day_key in per_day_taken:
                per_day_taken[day_key].add(med)

    # compute expected per day from latest prescription
    prescription = None
    patient = await patients_collection.find_one({"_id": patient_id})
    if not patient:
        try:
            patient = await patients_collection.find_one({"_id": ObjectId(patient_id)})
        except Exception:
            patient = None
    if patient:
        visits = patient.get("visits") or []
        if isinstance(visits, list) and visits:
            last = visits[-1]
            doc_stage = (last.get("stages") or {}).get("doctor") or {}
            data = doc_stage.get("data") or {}
            prescription = data.get("prescription")
        if not prescription:
            prescription = patient.get("prescription")

    expected_daily = _infer_expected_daily_meds_from_prescription(prescription or {})

    weekly = []
    for d in days:
        key = d.isoformat()
        taken_count = len(per_day_taken.get(key, set()))
        weekly.append({
            "day": WEEKDAY_LABELS[d.weekday()],
            "date": key,
            "taken": taken_count,
            "expected": expected_daily,
        })

    summary = {
        "taken_total": sum(x["taken"] for x in weekly),
        "expected_total": expected_daily * 7,
        "adherence_rate": (sum(x["taken"] for x in weekly) / (expected_daily * 7)) if expected_daily > 0 else None,
    }

    return {
        "criteria": {
            "patient_id": patient_id,
            "start": days[0].isoformat(),
            "end": days[-1].isoformat(),
            "tz": "IST",
        },
        "weekly": weekly,
        "summary": summary,
    }


# ---------------------------------------------------------
# GET UPCOMING APPOINTMENTS ENDPOINT
# ---------------------------------------------------------
@app.get("/patients/{patient_id}/upcoming-appointments")
async def get_upcoming_appointments(patient_id: str):
    """
    Returns the next upcoming appointment reminder for the patient.
    Queries notifications_collection for appointment_reminder type that hasn't been sent yet.
    """
    now_ist = datetime.now(IST).isoformat()

    # Find the next upcoming appointment (not sent, in the future)
    cursor = notifications_collection.find({
        "patient_id": patient_id,
        "metadata.type": "appointment_reminder",
        "send_at": {"$gte": now_ist},
        "sent": False
    }).sort("send_at", 1).limit(5)

    appointments = []
    async for doc in cursor:
        appointments.append({
            "id": str(doc.get("_id")),
            "title": doc.get("title"),
            "message": doc.get("message"),
            "scheduled_date": doc.get("send_at"),
            "milestone": doc.get("metadata", {}).get("milestone", ""),
        })

    # If no future appointments, check for the most recent past one
    if not appointments:
        cursor = notifications_collection.find({
            "patient_id": patient_id,
            "metadata.type": "appointment_reminder"
        }).sort("send_at", -1).limit(1)

        async for doc in cursor:
            appointments.append({
                "id": str(doc.get("_id")),
                "title": doc.get("title"),
                "message": doc.get("message"),
                "scheduled_date": doc.get("send_at"),
                "milestone": doc.get("metadata", {}).get("milestone", ""),
                "completed": True
            })

    return {
        "patient_id": patient_id,
        "appointments": appointments,
        "next_appointment": appointments[0] if appointments else None
    }


@app.on_event("startup")
async def start_background_tasks():
    """Start background notification dispatcher on app startup"""
    try:
        loop = asyncio.get_running_loop()
        task = loop.create_task(notification_dispatcher_loop())
        print("[DISPATCHER] Background task initialized")
        # Add a done callback to log if task exits unexpectedly
        def task_done_callback(t):
            try:
                t.result()
            except asyncio.CancelledError:
                pass  # Normal shutdown
            except Exception as e:
                print(f"[DISPATCHER] Task error: {e}")
        task.add_done_callback(task_done_callback)
    except Exception as e:
        print(f"[DISPATCHER] Startup error: {e}")


@app.on_event("shutdown")
async def shutdown_event():
    """Log when app is shutting down"""
    print("[SHUTDOWN] Application shutting down")